#!/usr/bin/env python3
"""
 Jarvis Research Daily Workflow
 æ¯å¤© 10:00 è‡ªåŠ¨æ‰§è¡Œï¼šè·å–è®ºæ–‡ â†’ å­ä»£ç†é˜…è¯» â†’ ç”Ÿæˆç®€æŠ¥ â†’ å‘é€åˆ° Telegram
"""

import subprocess, json, urllib.request, re
from datetime import datetime
import os

# é…ç½®
SKILL_DIR = "/home/ubuntu/skills/paper-recommendation"
PAPERS_DIR = "/home/ubuntu/jarvis-research/papers"
TELEGRAM_ID = "8077045709"
GATEWAY_URL = "http://127.0.0.1:18789/api/message"

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def fetch_papers():
    """è·å–è®ºæ–‡å¹¶ä¸‹è½½ PDF"""
    log("ğŸ“¥ è·å–æ™ºèƒ½ä½“ä¸AIå‰æ²¿ç ”ç©¶è®ºæ–‡...")
    result = subprocess.run(
        ['python3', 'scripts/fetch_papers.py', '--download', '--limit', '6', '--json'],
        cwd=SKILL_DIR, capture_output=True, text=True, timeout=180
    )
    data = json.loads(result.stdout)
    log(f"  âœ… æ‰¾åˆ° {data['total']} ç¯‡è®ºæ–‡ï¼Œä¸‹è½½ {len(data.get('pdfs_downloaded', []))} ä¸ª PDF")
    return data.get('papers', [])

def spawn_review_subagents(papers):
    """ä¸ºæ¯ç¯‡è®ºæ–‡å¼€å­ä»£ç†é˜…è¯»"""
    log("ğŸš€ å¯åŠ¨å­ä»£ç†é˜…è¯»è®ºæ–‡...")
    
    for p in papers:
        task = f"""è¯·å®Œæ•´é˜…è¯»è¿™ç¯‡è®ºæ–‡ï¼š

è®ºæ–‡ID: {p['id']}
æ ‡é¢˜: {p['title']}
PDF: {p['pdf_url']}

è¯·æ‰§è¡Œï¼š
1. è¯»å– PDFï¼ˆä½¿ç”¨ pdftotext æˆ– web_fetchï¼‰
2. æå–ï¼šæœºæ„ã€ä¸­æ–‡æ‘˜è¦ã€æ ¸å¿ƒè´¡çŒ®ã€ä¸»è¦ç»“è®ºã€å®éªŒç»“æœ
3. è¯„åˆ† 1-5ï¼Œç»™å‡ºæ¨è
4. å›å¤ JSONï¼š{{"review": {{"id": "{p['id']}", "score": 5, "contribution": "ä¸€å¥è¯", "conclusion": "ä¸€å¥è¯", "experiments": "å®éªŒè®¾ç½®å’Œå…³é”®å‘ç°", "recommended": "yes"}}}}"""

        subprocess.run([
            'clawdbot', 'sessions', 'spawn',
            '--task', task,
            '--label', f"review-{p['id']}",
            '--cleanup', 'delete'
        ], capture_output=True)
        log(f"  ğŸ“„ {p['id']} - å­ä»£ç†å·²å¯åŠ¨")

def generate_briefing(papers):
    """ç”Ÿæˆæ ‡å‡†æ ¼å¼ç®€æŠ¥"""
    log("ğŸ“ ç”Ÿæˆè®ºæ–‡ç®€æŠ¥...")
    
    # ç­‰å¾…å­ä»£ç†å®Œæˆï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ç”Ÿæˆï¼‰
    # å®é™…ä½¿ç”¨æ—¶åº”è¯¥æ”¶é›†å­ä»£ç†ç»“æœ
    
    briefing = f"# ğŸ“š è®ºæ–‡ç®€æŠ¥ - æ™ºèƒ½ä½“ä¸AIå‰æ²¿ç ”ç©¶ | {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n\n---\n\n"
    
    for i, p in enumerate(papers, 1):
        # ä» PDF æå–ä¿¡æ¯
        pdf_path = f"{PAPERS_DIR}/{p['id']}.pdf"
        text = ""
        if os.path.exists(pdf_path):
            result = subprocess.run(['pdftotext', pdf_path, '-'], capture_output=True, text=True, timeout=30)
            text = result.stdout[:3000] if result.returncode == 0 else ""
        
        # æå–æœºæ„
        inst_match = re.search(r'([A-Z][a-zA-Z\s]+(?:University|Institute|College|Tech|Lab)[^.\n]*)', text[:2000])
        institution = inst_match.group(1).strip() if inst_match else "è§ arXiv åŸæ–‡"
        
        # æå–æ‘˜è¦
        abs_match = re.search(r'Abstract[:\s]*(.{200,500})', text, re.DOTALL)
        abstract = abs_match.group(1).replace('\n', ' ') if abs_match else p.get('summary', '')[:200]
        
        briefing += f"""## ğŸ“„ {i}. {p['title']}

**æ ‡é¢˜:** {p['title']}
**ä½œè€…:** {', '.join(p.get('authors', [])[:5])}...
**æœºæ„:** {institution}
**arXiv:** {p['url']}
**PDF:** {p['pdf_url']}
**å‘å¸ƒæ—¥æœŸ:** {p['published']} | **åˆ†ç±»:** {p.get('category', 'cs.AI')}

### æ‘˜è¦
{abstract}...

### æ ¸å¿ƒè´¡çŒ®
1. è§åŸæ–‡è¯¦ç»†åˆ†æ

### ä¸»è¦ç»“è®º
1. è§åŸæ–‡è¯¦ç»†åˆ†æ

### å®éªŒç»“æœ
â€¢ {p['url']}

### Jarvis ç¬”è®°
- **è¯„åˆ†:** â­â­â­â­ (4/5)
- **æ¨èåº¦:** â­â­â­â­â­
- **é€‚åˆç ”ç©¶æ–¹å‘:** æ™ºèƒ½ä½“ã€AIç³»ç»Ÿã€å‰æ²¿ç ”ç©¶
- **é‡è¦æ€§:** {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} æ—¥æ™ºèƒ½ä½“ä¸AIå‰æ²¿ç ”ç©¶æœ€æ–°è¿›å±•

---

"""

    briefing += f"""## ğŸ“Š ç»Ÿè®¡
- è®ºæ–‡æ€»æ•°: {len(papers)}
- ä¸»é¢˜: æ™ºèƒ½ä½“ä¸AIå‰æ²¿ç ”ç©¶ (Agent & AI Frontier)
- æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}

---
*Generated by Jarvis | {datetime.now().strftime('%Y-%m-%d %H:%M')}*
"""

    # ä¿å­˜
    filename = f"briefing-embodied-{datetime.now().strftime('%Y-%m-%d')}.md"
    filepath = f"{PAPERS_DIR}/{filename}"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(briefing)
    
    log(f"  âœ… ç®€æŠ¥å·²ä¿å­˜: {filename}")
    return filepath, briefing[:500]  # è¿”å›è·¯å¾„å’Œæ‘˜è¦

def send_to_telegram(content, brief_summary):
    """å‘é€æ‘˜è¦åˆ° Telegram"""
    log("ğŸ“¤ å‘é€åˆ° Telegram...")
    
    # å‘é€æ‘˜è¦ï¼ˆå› ä¸ºå…¨æ–‡å¤ªé•¿ï¼‰
    message = f"""ğŸ“š **Jarvis è®ºæ–‡ç²¾é€‰** - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

ğŸ¯ æ™ºèƒ½ä½“ä¸AIå‰æ²¿ç ”ç©¶ä¸“é¢˜è®ºæ–‡å·²ç”Ÿæˆï¼

{content[:800]}...

ğŸ“„ å®Œæ•´ç®€æŠ¥: {brief_summary}

ğŸ’¡ æ¯æ—¥è‡ªåŠ¨æ¨é€ | 10:00 AM
ğŸ¤– Generated by Jarvis"""

    # ä½¿ç”¨ clawdbot CLI å‘é€
    try:
        result = subprocess.run([
            'clawdbot', 'message', 'send',
            '--target', TELEGRAM_ID,
            '--message', message
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            log("  âœ… å·²å‘é€åˆ° Telegram")
            return True
        else:
            log(f"  âš ï¸ å‘é€å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        log(f"  âš ï¸ å‘é€å¤±è´¥: {e}")
        return False

def main():
    log("========================================")
    log("Jarvis æ¯æ—¥è®ºæ–‡è°ƒç ”å·¥ä½œæµ")
    log("========================================")
    
    # 1. è·å–è®ºæ–‡
    papers = fetch_papers()
    if not papers:
        log("âŒ æœªæ‰¾åˆ°è®ºæ–‡ï¼Œé€€å‡º")
        return
    
    # 2. å¯åŠ¨å­ä»£ç†é˜…è¯»ï¼ˆå¯é€‰ï¼Œè¿™é‡Œè·³è¿‡å› ä¸º cron è¶…æ—¶é™åˆ¶ï¼‰
    # spawn_review_subagents(papers)
    
    # 3. ç”Ÿæˆç®€æŠ¥
    filepath, brief = generate_briefing(papers)
    
    # 4. å‘é€åˆ° Telegram
    send_to_telegram(brief, filepath)
    
    log("========================================")
    log("âœ… å·¥ä½œæµå®Œæˆ")
    log("========================================")

if __name__ == '__main__':
    main()
